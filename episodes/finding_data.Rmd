---
title: "Finding multi-dimensional biodiversity data"
teaching: 10
exercises: 2
editor_options: 
  markdown: 
    wrap: 50
---

::: questions

- Where do multi-dimensional biodiversity data live online?
- How can we use R APIs to quickly and reproducibly retrieve data?
- How can we combine online resources to assemble and store multi-dimensional datasets?

:::

::::::::::::::::::::::::::::::::::::: objectives

After following this episode, we intend that participants will be able to:

1. Effectively search for and find trait, sequence, and abundance data online given a taxon and research question 
2. Retrieve data from GEOME & GBIF using their R APIs and apply API principles to other databases
3. Organize a dataset of multiple dimensions of biodiversity from multiple online sources

::::::::::::::::::::::::::::::::::::::::::::::::

# Setup

Later on in this episode, we'll be working with some R packages that wrap the APIs of online repositories. 
Let's set those up now. 

```{r load packages}

library(rgbif)
library(devtools)
devtools::install_github("biocodellc/fimsR-access")
library(geomedb)

```

# Sources of multidimensional biodiversity data: large open-access databases

In recent years, large grant-supported open-access databases have been growing at an incredible pace. 
Databases like this host data from a wide variety of sources. Often data is accumulated from other large projects and organizations.
These platforms are then used to share and standardize data for the widest possible use. 

Many of these databases exist, but here are some examples:
  GBIF contains occurrance records of individuals assembled from dozens of smaller databases.
  GEOME (Genomic Observatories MetaDatabase) contains genetic data associated with specimens or samples from the field. 
  BOLD (Barcode of Life)
  EOL (Encyclopedia of Life)
  OTOL (Open Tree of Life) 
  
## Using R APIs to download database data 

An API is a set of tools that allows users to interact with a database, such as reading, writing, updating, and deleting data.
We can't go over all of these databases in detail, but let's cover some examples that illustrate some principles of how these APIs work for different data types. 

Lets get sequence data for mammals from GEOME. 
Data in GEOME is organized into Projects, lets look at some projects

```{r geome1}

listProjects()

```

The project with ID 1 looks interesting, let's download all sequences from this project

```{r geome2}

fasta <- querySanger('CYB', projects=list(1))

```
OTOL - phylogenies


## Common issues with API big data downloads 

Download limits

Query limits 

# Sources of MDBD: "small data" attached to papers 

A lot of useful data is not held in big databases, and is instead attached to papers. 
Searching on Google and Google Scholar can be an effective way to find such data. 
Let's search for "mammal trait database" on Google Scholar.

The first paper looks good, so let's look at the Supplementary Data which will contain their data.

Let's download and unzip the data. 

Reading the metadata file, we see that a certain data file contains the traits. Great! Let's read it into R. 

# Assembling a combined dataset


# Recap

::: keypoints

- Many sources exist online where multidimensional biodiversity data can be obtained
- APIs allow for fast and reproducible querying and downloading
- Storing multidimensional data efficiently is important

:::
    
